<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Robotic Interface Calibration via Probing - Mo Saeidi</title>
    <meta name="description" content="A project detailing the calibration of device interface elements (buttons, switches) using UR5e robot probing, segmented data acquisition based on gripper state, ArUco marker referencing, and statistical analysis with 3D visualization.">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&family=Roboto+Mono:wght@400;500&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"/>

    <link rel="stylesheet" href="../assets/css/base.css" />
    <link rel="stylesheet" href="../assets/css/layout.css" />
    <link rel="stylesheet" href="../assets/css/components/navbar.css" />
    <link rel="stylesheet" href="../assets/css/components/buttons.css" />
    <link rel="stylesheet" href="../assets/css/components/footer.css" />
    <link rel="stylesheet" href="../assets/css/pages/post.css" />

</head>
<body>
    <div class="page-wrapper">
        <header class="header">
            <nav class="navbar">
                <div class="container">
                    <button id="mobile-menu-btn" class="mobile-menu-btn" aria-label="Toggle Menu" aria-expanded="false">
                        <span class="bar"></span>
                        <span class="bar"></span>
                        <span class="bar"></span>
                    </button>
                    <ul class="nav-links">
                        <li><a href="../index.html">MoSa</a></li>
                        <li><a href="../projects.html">Projects</a></li>
                        <li><a href="../blog.html">Blog</a></li>
                        <li><a href="../academia.html">Academia</a></li>
                    </ul>
                </div>
            </nav>
        </header>

        <main class="main-content">
            <div class="container post-container">
                <article>
                    <header class="post-header">
                        <div class="post-meta">
                            <span class="post-category">Robotics & Calibration</span>
                            <time datetime="2025-04-15">April 15, 2025</time> </div>
                        <h1 class="post-title">Robotic Calibration of Device Interfaces via Probing and Statistical Analysis</h1>
                    </header>

                    <section class="post-content">
                        <p>
                            Accurately knowing the precise location and orientation (pose) of interaction elements like buttons, switches, and knobs on a physical device is crucial for automating tasks such as testing or remote operation using robots. This project details a methodology developed to calibrate these interface poses using a UR5e robot arm, leveraging physical probing, sensor state logic, and statistical analysis referenced to an ArUco marker.
                        </p>

                        <h2>1. Project Goal & Context</h2>
                        <p>
                            The objective was to determine the 3D pose of various interface elements on a target device relative to a fixed ArUco marker on the same device. This relative pose information allows calculating the absolute pose of any interface in the robot's base frame, simply by detecting the ArUco marker's current pose, creating a flexible "digital twin" configuration.
                        </p>

                        <h2>2. Methodology</h2>
                        <p>The process involved several key steps, implemented primarily in Python:</p>

                        <h3>Step 1: Data Acquisition Strategy</h3>
                        <p>
                            Two separate experiments were conducted using a UR5e robot. For each interface element:
                        </p>
                        <ul>
                            <li>The robot was manually guided or programmed to bring its tool tip (TCP) to the target point on the interface (e.g., center of a button).</li>
                            <li>Multiple (typically 3-7) readings of the robot's joint configurations were recorded at this target position.</li>
                            <li>**Segmentation:** To distinguish data belonging to one interface from the next without manual labeling in the data file, a specific procedure involving the robot's gripper was used. The gripper was opened (`GripperState = 0`) when moving away from an interface, then closed (`GripperState = 1`) before moving to and probing the *next* interface. This open/close cycle acts as a delimiter.</li>
                            <li>Data (joint poses, gripper state, etc.) was saved to CSV files (<code>waypoints_1.csv</code>, <code>waypoints_2.csv</code>).</li>
                            <li>The pose of the ArUco marker relative to the robot base (`T_base_aruco`) was determined and saved separately for each experiment setup (<code>environment_config_1.yaml</code>, <code>environment_config_2.yaml</code>).</li>
                        </ul>

                        <h3>Step 2: Data Processing & Segmentation</h3>
                        <p>
                            A script (`statistical_observation.py`) processed the raw CSV data:
                        </p>
                        <ol>
                            <li>**State Tracking:** It iterated through the CSV, monitoring the `GripperState` column.</li>
                            <li>**Delimiter Detection:** It detected the `0 -> 1` (open to close) transition to signify the start of probing a new interface and the `1 -> 0` (close to open) transition to signify the end.</li>
                            <li>**Filtering:**
                                <ul>
                                    <li>The *first* data point recorded immediately after the gripper closed (state became 1) was ignored, as it often corresponded to the robot moving into position rather than being at the target.</li>
                                    <li>Data blocks between an open-close-open cycle containing fewer than a minimum number of points (e.g., 3) were discarded as potential noise or incomplete measurements.</li>
                                </ul>
                            </li>
                            <li>**Forward Kinematics (FK):** For each valid data point (joint configuration), the script calculated the robot's TCP position in the base frame (`P_base_tcp`) using standard Denavit-Hartenberg parameters and the defined tool transformation (`T_6_TCP`).</li>
                            <li>**Coordinate Transformation:** Using the ArUco pose for that experiment (`T_base_aruco`), the base frame TCP positions were transformed into positions relative to the ArUco marker frame (`P_aruco_tcp = inv(T_base_aruco) * P_base_tcp`).</li>
                        </ol>

                        <h3>Step 3: Statistical Analysis & Relative Pose Generation</h3>
                        <p>
                            Using the processed points (`P_aruco_tcp`) grouped by interface:
                        </p>
                        <ol>
                            <li>**Combining Experiments:** Data points for the same interface from both experiments were combined.</li>
                            <li>**Mean Calculation:** The overall mean position (`P_aruco_interface_mean`) relative to the ArUco frame was calculated for each interface using the combined data.</li>
                            <li>**Relative SE(3) Pose:** A 4x4 homogeneous transformation matrix (`T_aruco_interface`) was constructed for each interface. This matrix represents the pose of the interface *relative* to the ArUco marker frame.
                                <ul>
                                    <li>**Orientation:** Assumed to be aligned with the ArUco marker (Identity rotation matrix).</li>
                                    <li>**Position:** Set to the calculated `P_aruco_interface_mean`.</li>
                                </ul>
                            </li>
                            <li>**Saving Results (`save_yaml.py`):** These relative `T_aruco_interface` matrices were saved into a structured YAML file (`interface_relative_poses.yaml`), mapping interface names to their relative poses.</li>
                        </ol>

                        <h3>Step 4: Visualization</h3>
                        <p>
                            Two types of visualizations were generated to understand the results:
                        </p>
                        <ol>
                            <li>**Statistical Analysis Plots (`statistical_observation.py`):** For each interface, a multi-panel plot compared the data from the two experiments (relative to ArUco). This included:
                                <ul>
                                    <li>A 3D scatter plot showing individual measurements and mean points.</li>
                                    <li>3D confidence ellipsoids indicating the spatial uncertainty/covariance for each experiment's measurements.</li>
                                    <li>Violin plots for X, Y, and Z coordinates showing the distribution, median, and spread of measurements for each experiment.</li>
                                </ul>
                            </li>
                            <li>**Transformation Frame Visualization (`visualize_tfs.py`):** Two separate 3D plots were generated, one for each experiment. Each plot showed:
                                <ul>
                                    <li>The pose of the ArUco marker in the base frame (`T_base_aruco`).</li>
                                    <li>The calculated absolute pose of each interface in the base frame (`T_base_interface = T_base_aruco @ T_aruco_interface`).</li>
                                    <li>Coordinate frames were drawn using RGB for XYZ axes for clarity.</li>
                                </ul>
                            </li>
                        </ol>
                        <figure class="post-figure">
                             <img src="../assets/images/projects/interface-calibration/interface_analysis_example.png" alt="Example statistical analysis plot for one interface showing 3D scatter, ellipsoids and violin plots" class="post-image">
                             <figcaption class="post-caption">
                                 <strong>Figure 1:</strong> Example analysis plot for a single interface, comparing data distribution and uncertainty between Experiment 1 and Experiment 2 (relative to ArUco frame).
                             </figcaption>
                        </figure>

                        <figure class="post-figure">
                            <img src="../assets/images/projects/interface-calibration/interface_tf_visualization.png" alt="Example visualization showing coordinate frames of ArUco marker and interfaces in robot base frame" class="post-image">
                             <figcaption class="post-caption">
                                 <strong>Figure 2:</strong> Example visualization showing the calculated poses (coordinate frames) of the ArUco marker and several interfaces within the robot's base frame for one experiment.
                             </figcaption>
                        </figure>

                        <h2>4. Results & Discussion</h2>
                        <p>
                            The process successfully generated a YAML configuration file containing the calibrated relative poses of the device interfaces. The statistical visualizations provided valuable insights into:
                        </p>
                        <ul>
                            <li>The consistency (or inconsistency) of measurements between the two different experimental setups.</li>
                            <li>The spatial uncertainty associated with probing each interface, visualized by the confidence ellipsoids.</li>
                            <li>The distribution of measurements along each axis (X, Y, Z), highlighting any potential skew or outliers.</li>
                        </ul>
                        <p>
                            The final YAML file serves as a robust way to locate interfaces. By simply finding the ArUco marker in the robot's view, the pose of any calibrated interface can be instantly calculated using `T_base_interface = T_base_aruco @ T_aruco_interface`.
                        </p>

                        <div class="post-summary">
                            <h2>Key Takeaways</h2>
                            <ul class="summary-list">
                                <li>Developed a pipeline for calibrating interface poses using robot probing and ArUco marker referencing.</li>
                                <li>Implemented a novel data segmentation technique based on gripper state transitions.</li>
                                <li>Utilized statistical analysis (mean, covariance, confidence ellipsoids) to assess measurement quality and combine data from multiple experiments.</li>
                                <li>Generated a reusable YAML configuration mapping interface names to their poses relative to the ArUco marker.</li>
                                <li>Created informative visualizations for data analysis and final pose verification.</li>
                            </ul>
                        </div>

                        <h2>5. Limitations & Future Work</h2>
                        <ul>
                            <li>Accuracy is highly dependent on the robot's kinematic calibration and the accuracy of the TCP definition.</li>
                            <li>The probing method relies on reaching pre-defined points; incorporating force feedback could allow for contact-based probing, potentially improving robustness to slight variations.</li>
                            <li>The segmentation logic assumes a clean open-close-open sequence; handling interruptions or unexpected state changes could be improved.</li>
                            <li>Explicitly calibrating the orientation of interfaces (if they are not aligned with the ArUco marker) would require different probing strategies (e.g., touching multiple points on the interface).</li>
                        </ul>

                        <h2>Conclusion</h2>
                        <p>
                            This project demonstrates a practical method for calibrating the location of multiple interaction points on a device using a standard robotic arm and simple gripper feedback. By combining kinematic calculations, coordinate transformations, statistical averaging, and clear visualization, it produces a useful relative pose configuration that simplifies future automated interaction tasks with the device.
                        </p>
                        <hr>
                        <p><em>Questions or thoughts on this project? Connect via the <a href="../academia.html#contact-simplified">contact form</a> or <a href="https://www.linkedin.com/in/mo-saeidi-21a00015a/" target="_blank">LinkedIn</a>.</em></p>
                    </section>
                </article>

                <a href="../blog.html" class="back-to-blog"><i class="fas fa-arrow-left"></i> Back to Blog List</a>
            </div>
        </main>

        <footer class="footer">
            <div class="container">
                <p>&copy; <span id="current-year"></span> Mo Saeidi. All rights reserved.</p>
            </div>
        </footer>
    </div>
    <script src="../assets/js/main.js"></script>
</body>
</html>